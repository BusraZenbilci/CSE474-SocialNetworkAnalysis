{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-8al5UMyaH_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae43b39a-7b78-4c25-aff4-8f8b4600f7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.10/dist-packages (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!pip install zipfile36"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRDruNOIzNDm",
        "outputId": "7b9183f8-833c-424a-99d7-6d82ca8e4628"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "RlzwD4CN_KSY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and extract the zip archive\n",
        "zip_file_path = '/content/drive/MyDrive/social_network/TwiBot-20/Twibot-20.zip'\n",
        "extract_dir = '/content/drive/MyDrive/social_network/MyTwiBot'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "5sMHYw8A93kf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON files\n",
        "extract_dir = '/content/drive/MyDrive/social_network/MyTwiBot/Twibot-20'\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "train_data = load_json(os.path.join(extract_dir, 'train.json'))\n",
        "dev_data = load_json(os.path.join(extract_dir, 'dev.json'))\n",
        "test_data = load_json(os.path.join(extract_dir, 'test.json'))\n",
        "all_data = train_data + dev_data + test_data\n",
        "\n"
      ],
      "metadata": {
        "id": "br9EZx_N8vvt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature Extraction\n",
        "def extract_features(data):\n",
        "    features = []\n",
        "    for user in data:\n",
        "        profile = user.get('profile', {})\n",
        "        created_at = pd.to_datetime(profile.get('created_at', '1970-01-01'), errors='coerce')\n",
        "        if created_at.tzinfo is None:\n",
        "            created_at = created_at.tz_localize('UTC')\n",
        "        profile_features = {\n",
        "            'followers_count': int(profile.get('followers_count', 0)),\n",
        "            'friends_count': int(profile.get('friends_count', 0)),\n",
        "            'statuses_count': int(profile.get('statuses_count', 0)),\n",
        "            'verified': int(profile.get('verified', 'False').strip() == 'True'),\n",
        "            'account_age_days': (pd.Timestamp.now(tz='UTC') - created_at).days\n",
        "        }\n",
        "        features.append(profile_features)\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "node_features = extract_features(all_data)\n",
        "\n",
        "# Extract TF-IDF features from tweets\n",
        "def extract_tweet_features(data):\n",
        "    tweets = []\n",
        "    for user in data:\n",
        "        user_tweets = user.get('tweet', [])\n",
        "        if user_tweets is None:\n",
        "            user_tweets = [\"\"]  # Add a blank string if there are no tweets\n",
        "        tweets.append(\" \".join(user_tweets))  # Combine all tweets of a user into a single string\n",
        "    vectorizer = TfidfVectorizer(max_features=100)\n",
        "    tfidf_matrix = vectorizer.fit_transform(tweets)\n",
        "    return tfidf_matrix\n",
        "\n",
        "tfidf_matrix = extract_tweet_features(all_data)\n",
        "\n",
        "# Ensure the number of samples matches\n",
        "assert node_features.shape[0] == tfidf_matrix.shape[0], \"Mismatch in the number of samples between node features and TF-IDF features\"\n",
        "\n",
        "# Combine all features\n",
        "node_features = np.hstack([node_features, tfidf_matrix.toarray()])\n",
        "\n",
        "# Encode labels\n",
        "labels = [user['label'] for user in all_data]\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Split the node features and labels into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(node_features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier with adjusted hyperparameters\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "train_report = classification_report(y_train, y_train_pred, output_dict=True)\n",
        "test_report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "\n",
        "print(\"Random Forest Training Set Evaluation:\")\n",
        "print(pd.DataFrame(train_report).transpose())\n",
        "\n",
        "print(\"Random Forest Test Set Evaluation:\")\n",
        "print(pd.DataFrame(test_report).transpose())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2AmY-oZ_nCA",
        "outputId": "a06688d8-67dc-41de-e858-6d9d5f1beca3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Training Set Evaluation:\n",
            "              precision    recall  f1-score      support\n",
            "0              0.960445  0.806036  0.876492  3645.000000\n",
            "1              0.864533  0.973883  0.915956  4633.000000\n",
            "accuracy       0.899976  0.899976  0.899976     0.899976\n",
            "macro avg      0.912489  0.889959  0.896224  8278.000000\n",
            "weighted avg   0.906765  0.899976  0.898579  8278.000000\n",
            "Random Forest Test Set Evaluation:\n",
            "              precision    recall  f1-score      support\n",
            "0              0.911719  0.733040  0.812674  1592.000000\n",
            "1              0.812610  0.942229  0.872633  1956.000000\n",
            "accuracy       0.848365  0.848365  0.848365     0.848365\n",
            "macro avg      0.862164  0.837635  0.842653  3548.000000\n",
            "weighted avg   0.857081  0.848365  0.845729  3548.000000\n"
          ]
        }
      ]
    }
  ]
}